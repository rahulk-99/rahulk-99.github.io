<!DOCTYPE html>
<html lang="en">

<head>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-BLK4KJZ3L6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-BLK4KJZ3L6');
  </script>

  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>Rahul Kumar Portfolio</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/robo.png" rel="icon">
  <link href="assets/img/robo.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/main.css?v=1.1" rel="stylesheet">

  <!-- =======================================================
  * Template Name: MyResume
  * Template URL: https://bootstrapmade.com/free-html-bootstrap-template-my-resume/
  * Updated: Jun 29 2024 with Bootstrap v5.3.3
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body class="index-page">

  <header id="header" class="header d-flex flex-column flex-xl-row align-items-xl-center justify-content-center">

    <i class="header-toggle d-xl-none bi bi-list"></i>

    <div class="theme-toggle" id="theme-toggle" title="Toggle Dark Mode">
      <i class="bi bi-moon"></i>
    </div>

    <nav id="navmenu" class="navmenu">
      <ul>
        <li><a href="#hero" class="active"><i class="bi bi-house navicon"></i><span>Home</span></a></li>
        <li><a href="#about"><i class="bi bi-person navicon"></i><span>About Me</span></a></li>
        <li><a href="#education"><i class="bi bi-mortarboard navicon"></i><span>Education</span></a></li>
        <li><a href="#Experience"><i class="bi bi-images navicon"></i><span>Experience</span></a></li>
        <li><a href="#projects"><i class="bi bi-hdd-stack navicon"></i><span>Projects</span></a></li>
        <li><a href="#extra"><i class="bi bi-file-earmark-text navicon"></i><span>Publication</span></a></li>
        <li><a href="#extra"><i class="bi bi-file-earmark-text navicon"></i><span>Activities</span></a></li>

      </ul>
    </nav>

  </header>

  <main class="main">

    <!-- Hero Section -->
    <section id="hero" class="hero section light-background">

      <img src="assets/img/robo_bg.png" alt="">

      <div class="container" data-aos="zoom-out">
        <div class="row justify-content-center">
          <div class="col-lg-9">
            <h2>Rahul Kumar</h2>
            <p>I'm <span class="typed" data-typed-items="a Robotics Engineer, a Graduate Student"></span><span
                class="typed-cursor typed-cursor--blink" aria-hidden="true"></span></p>
            <h5>Robot Learning, Machine Learning, Computer Vision, Planning and Controls</h5>
            <div class="social-links">
              <a href="#projects" class="bi-journal-richtext">PROJECTS</a>
              <!--               <a href="https://drive.google.com/file/d/1yOBiH2f2XlGfcOJZa62_uNmvwBO-6fig/view?usp=drive_link" class="bi-journal-richtext">RESUME</a> -->
              <a href="https://github.com/rahulk-99"><i class="bi bi-github"></i></a>
              <a href="https://www.linkedin.com/in/rahul-kumar4/"><i class="bi bi-linkedin"></i></a>
              <a href="https://scholar.google.com/citations?user=hO-8jtoAAAAJ&hl=en&authuser=2"><i
                  class="bi bi-mortarboard-fill"></i></a>
            </div>
          </div>
        </div>
      </div>


      <!-- Timeline Overlay -->
      <div class="timeline-overlay">
        <div class="timeline-container" data-aos="fade-left">
          <h3 class="timeline-title">Latest Updates</h3>


          <!-- Timeline Item 1 -->
          <div class="timeline-item">
            <div class="timeline-dot"></div>
            <div class="timeline-content">
              <h3>June 2025</h3>
              <div class="timeline-card">
                <h4>Joined CapSen Robotics as Robotics Software Intern - Pittsburgh, PA</h4>
                <!--                 <p>Joined CapSen Robotics as Robotics Software Intern - Pittsburgh - PA.</p> -->
              </div>
            </div>
          </div>

          <!-- Timeline Item 1 -->
          <div class="timeline-item">
            <div class="timeline-dot"></div>
            <div class="timeline-content">
              <h3>May 2025</h3>
              <div class="timeline-card">
                <h4>Guest Visit to Microsoft's Advanced Autonomy & Applied Robotics (A3R) Center - VA, USA </h4>
                <!--                 <p>Joined CapSen Robotics as Robotics Software Intern - Pittsburgh - PA.</p> -->
              </div>
            </div>
          </div>


          <!-- Timeline Item 1 -->
          <div class="timeline-item">
            <div class="timeline-dot"></div>
            <div class="timeline-content">
              <h3>March 2025</h3>
              <div class="timeline-card">
                <h4>Volunteered as Robot Inspector at FIRST Robotics Competition</h4>
                <!--                 <p>Served as a technical inspector for high school robotics teams at FRC District Event.</p> -->
              </div>
            </div>
          </div>

          <!-- Timeline Item 2 -->
          <div class="timeline-item">
            <div class="timeline-dot"></div>
            <div class="timeline-content">
              <h3>August 2024</h3>
              <div class="timeline-card">
                <h4> Started my Master's in Robotics at the University of Maryland, College Park</h4>
                <!--                 <p>Began Master's in Robotics Engineering at University of Maryland, College Park.</p> -->
              </div>
            </div>
          </div>

          <!-- Timeline Item 3 -->
          <div class="timeline-item">
            <div class="timeline-dot"></div>
            <div class="timeline-content">
              <h3>December 2022</h3>
              <div class="timeline-card">
                <h4> Presented Paper, as first author, at International Conference - 67th ISTAM at IIT Mandi. Later
                  selected & published in International Journal in Springer Nature</h4>
                <!--                 <p>Presented Paper at International Conference - 67th ISTAM at IIT Mandi</p> -->
              </div>
            </div>
          </div>

        </div>
      </div>

    </section><!-- /Hero Section -->

    <!-- About Section -->
    <section id="about" class="about section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>About Me</h2>
        <!-- <a href="#projects" class="goto-projects">Go To Projects <i class="bi bi-arrow-down"></i></a> -->
      </div><!-- End Section Title -->

      <div class="container" data-aos="fade-up" data-aos-delay="100">

        <div class="row gy-4 justify-content-center align-items-center">
          <div class="col-lg-3">
            <img src="assets/img/my_dp_5.jpg" class="img-fluid" loading="lazy" alt="">
          </div>
          <div class="col-lg-8 content">

            <p class="py-4">
              Hi, I am Rahul Kumar. I am a Master's student in <strong>Robotics Engineering</strong> at the <a
                href="https://robotics.umd.edu/">University of Maryland</a>, College Park (graduating May 2026),
              specializing in building autonomous systems that integrate Robot Learning, Perception, Physical AI, and
              Motion Planning. Currently, as a Research Assistant at the GAMMA Lab under Prof. <a
                href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a>, I am
              architecting an end-to-end autonomous navigation stack that integrates semantic segmentation and sensor
              fusion into high-fidelity 3D world models to drive geometry-aware VLA policies trained on internet-scale
              data for safe navigation.

              <br><br>
              Recently, as a <strong>Robotics Software Intern</strong> at <a
                href="https://www.capsenrobotics.com/">CapSen Robotics</a>, I established a Sim-to-Real Robot Learning
              framework by modeling
              a high-fidelity digital twin of an industrial manipulator in Isaac Sim to train and deploy RL policies for
              hybrid pick-and-place.
              Additionally, I implemented Foundation Models for 3D pose estimation using robust MLOps practices.

              <br><br>Previously, I spent 3.5 years as an R&D Engineer at Bharat Electronics, where I led the
              development of an
              underwater object detection device spanning from conceptualization to field validation, utilizing GANs for
              data augmentation. With a Mechanical Engineering degree from the <a href="https://www.iitdh.ac.in/">Indian
                Institute of Technology (IIT)</a> Dharwad, I bring a holistic perspective
              that bridges the gap between software intelligence and physical hardware mechanics.

              <br><br>I actively engage in brainstorming sessions and approach problems with a creative mindset and
              innovative ideas. Outside of academics and work, I enjoy playing table tennis and exploring music.

              <br><br>
              I am actively <strong>seeking full-time opportunities</strong> where I can apply my skills in Robotics and
              AI. Feel free to check out my <a href="#projects">projects</a> to learn more about my work and
              experiences.
              <!-- I am actively looking for internship/Co-Op opportunities in robotics, AI, and autonomous systems for summer/fall 2025. -->
            </p>


          </div>
        </div>
      </div>

    </section><!-- /About Section -->

    <!-- Education Section -->
    <section id="education" class="resume section">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-10 col-md-12">
            <div class="section-title text-center">
              <div class="title-with-link">
                <h2>Education</h2>
                <a href="#projects" class="goto-projects">Go To Projects <i class="bi bi-arrow-down"></i></a>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-10 col-md-12" data-aos="fade-up" data-aos-delay="200">

            <!-- Masters -->
            <div class="resume-item">
              <div class="experience-header" data-bs-toggle="collapse" data-bs-target="#education-masters" role="button"
                aria-expanded="false" aria-controls="education-masters">
                <div class="d-flex justify-content-between align-items-center">
                  <div style="flex-grow: 1;">
                    <div class="d-flex justify-content-between align-items-center">
                      <b>University of Maryland, College Park</b>
                      <span class="experience-date">Aug 2024 – May 2026</span>
                    </div>
                    <h5><i>Masters in Robotics Engineering</i></h5>
                  </div>
                  <i class="bi bi-chevron-down ms-3"></i>
                </div>
              </div>
              <div class="collapse experience-content" id="education-masters">
                <h6 class="mb-3"><strong>Courses:</strong></h6>

                <div class="mb-3">
                  <strong><u>Robotics Software & Systems</u></strong>
                  <ul class="mt-1 mb-0">
                    <li>Real-Time Operating Systems (RTOS)</li>
                    <li>Software Development for Robotics</li>
                    <li>Robot Programming</li>
                  </ul>
                </div>

                <div class="mb-3">
                  <strong><u>AI & Robot Learning</u></strong>
                  <ul class="mt-1 mb-0">
                    <li>Multimodal Foundation Models</li>
                    <li>Robot Learning</li>
                    <li>Machine Learning</li>
                  </ul>
                </div>

                <div>
                  <strong><u>Perception & Autonomy</u></strong>
                  <ul class="mt-1 mb-0">
                    <li>Perception for Autonomous Systems</li>
                    <li>Planning for Autonomous Systems</li>
                    <li>Robot Modeling</li>
                    <li>Control of Robotic Systems</li>
                  </ul>
                </div>
              </div>
            </div>

            <!-- Bachelors -->
            <div class="resume-item">
              <div class="experience-header">
                <div style="flex-grow: 1;">
                  <div class="d-flex justify-content-between align-items-center">
                    <b>Indian Institute of Technology (IIT), Dharwad - India</b>
                    <span class="experience-date">Aug 2016 – Jul 2020</span>
                  </div>
                  <h5><i>Bachelor of Technology in Mechanical Engineering</i></h5>
                </div>
              </div>
            </div>

          </div>
        </div>
      </div>
    </section><!-- /Education Section -->


    <!-- Resume Section -->
    <section id="Experience" class="resume section">

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-10 col-md-12">
            <div class="section-title text-center">
              <div class="title-with-link">
                <h2>Professional Experience</h2>
                <a href="#projects" class="goto-projects">Go To Projects <i class="bi bi-arrow-down"></i></a>
              </div>
              <h6>3.5+ years</h6>
            </div>
          </div>
        </div>
      </div>

      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-10 col-md-12" data-aos="fade-up" data-aos-delay="200">


            <!-- Gamma Lab Research Assistant -->
            <div class="resume-item">
              <div class="experience-header" data-bs-toggle="collapse" data-bs-target="#gamma-research" role="button"
                aria-expanded="false" aria-controls="gamma-research">
                <div class="d-flex justify-content-between align-items-center">
                  <div style="flex-grow: 1;">
                    <h4 class="d-flex justify-content-between align-items-center">
                      <b>Research Assistant</b>
                      <span class="experience-date">Sept 2025 – Present</span>
                    </h4>
                    <h5><i>GAMMA Lab, University of Maryland, College Park - USA</i></h5>
                    <div class="resume-skills">
                      <span class="skill-badge">Autonomous Vehicle</span>
                      <span class="skill-badge">VLA</span>
                      <span class="skill-badge">Large-Scale Data</span>
                      <span class="skill-badge">Sensor Fusion (Camera, LiDAR, IMU)</span>
                      <span class="skill-badge">Semantic Segmentation</span>
                      <span class="skill-badge">Motion Planning</span>
                      <span class="skill-badge">3D Perception</span>
                    </div>
                  </div>
                  <i class="bi bi-chevron-down"></i>
                </div>
              </div>
              <div class="collapse experience-content" id="gamma-research">
                <p><strong>Under Prof. Dinesh Manocha</strong> | <a
                    href="https://github.com/rahulk-99/Autonomous-navigation-stack" target="_blank">GitHub</a></p>
                <ul>
                  <li>Developed full-stack navigation stack to guide an autonomous mobile robot safely through dynamic
                    environments with pedestrians, vehicles & traffic signs.</li>
                  <li>Built real-time sensor fusion (Camera, 3D Lidar), semantic segmentation layer with terrain
                    mapping, and multi-object 3D tracking pipelines, achieving high-fidelity world modeling and robust
                    state estimation.</li>
                  <li>Building multimodal VLA-based control pipelines for real-world autonomous navigation tasks.</li>
                </ul>
              </div>
            </div>

            <!-- Internship -->
            <div class="resume-item">
              <div class="experience-header" data-bs-toggle="collapse" data-bs-target="#software-intern" role="button"
                aria-expanded="false" aria-controls="software-intern">
                <div class="d-flex justify-content-between align-items-center">
                  <div style="flex-grow: 1;">
                    <h4 class="d-flex justify-content-between align-items-center">
                      <b>Robotics Software Intern & Co-op</b>
                      <span class="experience-date">June 2025 – Dec 2025</span>
                    </h4>
                    <h5><i>CapSen Robotics Inc, Pittsburgh, PA - USA</i></h5>
                    <div class="resume-skills">
                      <span class="skill-badge">Isaac Sim & Lab</span>
                      <span class="skill-badge">Reinforcement Learning</span>
                      <span class="skill-badge">Sim2Real</span>
                      <span class="skill-badge">Industrial manipulator</span>
                      <span class="skill-badge">MLOps</span>
                      <span class="skill-badge">Foundation Models</span>
                      <span class="skill-badge">TensorRT</span>
                      <span class="skill-badge">ROS</span>
                      <span class="skill-badge">C++</span>
                      <span class="skill-badge">YOLO</span>
                    </div>
                  </div>
                  <i class="bi bi-chevron-down"></i>
                </div>
              </div>
              <div class="collapse experience-content" id="software-intern">
                <p>
                  I established a Sim-to-Real Robot Learning framework by modeling a high-fidelity digital twin of an
                  industrial manipulator in Isaac Sim to train and deploy RL policies for hybrid pick-and-place.
                  Additionally, I implemented Foundation Models for 3D pose estimation using robust MLOps practices.
                  <br><br>
                  <strong>Co-op Extension:</strong>
                <ul>
                  <li>Developed ROS-based Multi-modal perception pipelines using Machine Learning for autonomous
                    inspection.</li>
                  <li>Engineered MLOps for large-scale perception datasets - deployment, monitoring, data curation.</li>
                </ul>
                <br>
                <!-- - Demonstrated successful Sim2Real transfer by deploying the validated policy onto the physical robot, bypassing the existing C++ planning stack ensuring hardware-safe execution

              <br>
              - Built an end-to-end pipeline with a stereo vision camera and implemented a Foundation Vision Model to generate point clouds accurate enough to estimate object poses.

              <br>
              - Optimized a PyTorch model with TensorRT, reducing inference time by 90% (10s to 1s) for point cloud generation. -->
                </p>
              </div>
            </div>

            <!-- Graduate Research Assistant -->
            <!--
            <div class="resume-item">
              <div class="experience-header" data-bs-toggle="collapse" data-bs-target="#grad-research-assistant"
                role="button" aria-expanded="false" aria-controls="grad-research-assistant">
                <div class="d-flex justify-content-between align-items-center">
                  <div style="flex-grow: 1;">
                    <h4 class="d-flex justify-content-between align-items-center">
                      <b>Graduate Research Assistant</b>
                      <span class="experience-date">Nov 2024 – Mar 2025</span>
                    </h4>
                    <h5><i>University of Maryland, College Park - USA</i></h5>
                    <div class="resume-skills">
                      <span class="skill-badge">Isaac Sim</span>
                      <span class="skill-badge">Pegasus Simulator</span>
                      <span class="skill-badge">Soft Actor-Critic (SAC)</span>
                      <span class="skill-badge">Reinforcement Learning</span>
                      <span class="skill-badge">Real-to-Sim</span>
                      <span class="skill-badge">UAV Control</span>
                      <span class="skill-badge">Python</span>
                    </div>
                  </div>
                  <i class="bi bi-chevron-down"></i>
                </div>
              </div>
              <div class="collapse experience-content" id="grad-research-assistant">
                <p>
                  Developed reinforcement learning-based motion planning for a dual-environment drone with an integrated
                  manipulator. Simulation done in Isaac Sim
                </p>
              </div>
            </div>
            -->

            <!-- Product Development Engineer -->
            <div class="resume-item">
              <div class="experience-header" data-bs-toggle="collapse" data-bs-target="#product-dev" role="button"
                aria-expanded="false" aria-controls="product-dev">
                <div class="d-flex justify-content-between align-items-center">
                  <div style="flex-grow: 1;">
                    <h4 class="d-flex justify-content-between align-items-center">
                      <b>Product Development Engineer - R&D</b>
                      <span class="experience-date">Feb 2021 – July 2024</span>
                    </h4>
                    <h5><i>Bharat Electronics Limited, Bangalore - India</i></h5>
                    <div class="resume-skills">
                      <span class="skill-badge">Generative AI</span>
                      <span class="skill-badge">GAN</span>
                      <span class="skill-badge">YOLOv8</span>
                      <span class="skill-badge">RT-DETR</span>
                      <span class="skill-badge">Computer Vision</span>
                      <span class="skill-badge">Underwater Systems</span>
                      <span class="skill-badge">Rapid Prototyping</span>
                      <span class="skill-badge">MLOps</span>
                      <span class="skill-badge">Python</span>
                    </div>
                  </div>
                  <i class="bi bi-chevron-down"></i>
                </div>
              </div>
              <div class="collapse experience-content" id="product-dev">
                <p>
                  I led the end-to-end development of advanced underwater systems. My primary project was a Li-Fi
                  enabled object detection device, where I leveraged GANs to solve data scarcity and significantly boost
                  model performance in challenging conditions.
                  <br><br>Executed the end-to-end development of a sonar system, from ideation and design to
                  implementation and testing. Demonstrated proficiency in integrating hardware and software solutions,
                  ensuring seamless functionality and alignment with industry standards for underwater applications.
                </p>
              </div>
            </div>

            <!-- Research Assistant -->
            <div class="resume-item">
              <div class="experience-header" data-bs-toggle="collapse" data-bs-target="#research-assist" role="button"
                aria-expanded="false" aria-controls="research-assist">
                <div class="d-flex justify-content-between align-items-center">
                  <div style="flex-grow: 1;">
                    <h4 class="d-flex justify-content-between align-items-center">
                      <b>Research Assistant</b>
                      <span class="experience-date">July 2020 – Feb 2021</span>
                    </h4>
                    <h5><i>IIT Dharwad - India</i></h5>
                    <div class="resume-skills">
                      <span class="skill-badge">Machine Learning</span>
                      <span class="skill-badge">LUA Scripting</span>
                      <span class="skill-badge">Ensemble Learning</span>
                      <span class="skill-badge">XGBoost</span>
                      <span class="skill-badge">Random Forest</span>
                      <span class="skill-badge">Python</span>
                    </div>
                  </div>
                  <i class="bi bi-chevron-down"></i>
                </div>
              </div>
              <div class="collapse experience-content" id="research-assist">
                <ul class="text-start ps-3 fs-6">
                  <li>Engineered an ML workflow to create a novel predictive model for MEMS actuators, resulting in a
                    first author publication: <a href="https://link.springer.com/article/10.1007/s12572-023-00357-0"
                      target="_blank">[Springer Nature]</a>.</li>
                  <li>Generated a comprehensive synthetic dataset from numerous physics-based FEM simulations using
                    <strong>LUA Scripting</strong>.
                  </li>
                  <li>Developed a weighted-average ensemble of regressors (<strong>Random Forest, SVM, XGBoost</strong>)
                    to derive the final predictive model from the simulated data.</li>
                  <li>Benchmarked the model against established methods, reducing prediction error <strong>~40%</strong>
                    down to less than 7%.</li>
                </ul>
              </div>
            </div>

            <!-- Project Consultant -->
            <!--
            <div class="resume-item">
              <div class="experience-header" data-bs-toggle="collapse" data-bs-target="#project-consultant"
                role="button" aria-expanded="false" aria-controls="project-consultant">
                <div class="d-flex justify-content-between align-items-center">
                  <div style="flex-grow: 1;">
                    <h4 class="d-flex justify-content-between align-items-center">
                      <b>Project Consultant (Co-op)</b>
                      <span class="experience-date">Aug 2019 – June 2020</span>
                    </h4>
                    <h5><i>MAN Energy Solutions India</i></h5>
                  </div>
                  <i class="bi bi-chevron-down"></i>
                </div>
              </div>
              <div class="collapse experience-content" id="project-consultant">
                <p>
                  Developed MATLAB-based code for stability analysis of autonomous weight-lifting systems, establishing
                  the first framework within the company.
                </p>
              </div>
            </div>
            -->

            <!-- Automation Intern -->
            <!--
            <div class="resume-item">
              <div class="experience-header" data-bs-toggle="collapse" data-bs-target="#automation-intern" role="button"
                aria-expanded="false" aria-controls="automation-intern">
                <div class="d-flex justify-content-between align-items-center">
                  <div style="flex-grow: 1;">
                    <h4 class="d-flex justify-content-between align-items-center">
                      <b>Automation Intern</b>
                      <span class="experience-date">June 2019 – July 2019</span>
                    </h4>
                    <h5><i>Aequs Aerospace Pvt. Ltd, Belgaum - India</i></h5>
                  </div>
                  <i class="bi bi-chevron-down"></i>
                </div>
              </div>
              <div class="collapse experience-content" id="automation-intern">
                <p>
                  Optimized path planning for an articulated 6-DOF robotic arm, reducing manufacturing costs by 42%.
                </p>
              </div>
            </div>
            -->

          </div>
        </div>
      </div>

    </section><!-- /Resume Section -->

    <style>
      .resume-item {
        margin-bottom: 25px;
        padding: 20px;
        border-radius: 10px;
        box-shadow: 0 2px 15px rgba(0, 0, 0, 0.1);
        background: #fff;
        min-height: auto;
        /* Changed from fixed height to auto */
        transition: all 0.3s ease;
      }

      body.dark-mode .resume-item {
        background: var(--surface-color);
        box-shadow: 0 2px 15px rgba(255, 255, 255, 0.05);
      }

      .experience-header {
        cursor: pointer;
        padding: 10px;
        border-radius: 5px;
        transition: all 0.3s ease;
      }

      .experience-header:hover {
        background-color: rgba(0, 0, 0, 0.05);
      }

      .experience-header h4 {
        margin-bottom: 10px;
        display: flex;
        flex-wrap: wrap;
        align-items: center;
        gap: 15px;
      }

      .experience-date {
        font-size: 0.9em;
        color: #666;
        white-space: nowrap;
        margin-left: 15px;
        text-align: right;
        min-width: 180px;
      }

      .experience-content {
        margin-top: 15px;
        padding: 15px;
        border-top: 1px solid #eee;
        transition: all 0.3s ease;
      }

      .bi-chevron-down {
        transition: transform 0.3s ease;
        font-size: 1.2rem;
        color: #666;
      }

      .collapse.show+.experience-header .bi-chevron-down,
      .experience-header[aria-expanded="true"] .bi-chevron-down {
        transform: rotate(180deg);
      }

      /* Responsive Styles */
      @media (max-width: 768px) {
        .resume-item {
          padding: 15px;
        }

        .experience-header h4 {
          font-size: 1.1rem;
          flex-direction: column;
          align-items: flex-start;
          gap: 5px;
        }

        .experience-date {
          margin-left: 0;
        }

        .experience-content {
          padding: 10px;
        }
      }
    </style>

    <script>
      document.addEventListener('DOMContentLoaded', function () {
        // Add click event listeners to all experience headers
        document.querySelectorAll('.experience-header').forEach(header => {
          header.addEventListener('click', function () {
            const chevron = this.querySelector('.bi-chevron-down');
            const isExpanded = this.getAttribute('aria-expanded') === 'true';

            // Rotate chevron when clicked
            chevron.style.transform = isExpanded ? 'rotate(0deg)' : 'rotate(180deg)';
          });
        });
      });
    </script>

    <!-- Portfolio Section -->
    <section id="projects" class="portfolio section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Projects</h2>
        <!-- <p>Magnam dolores commodi suscipit. Necessitatibus eius consequatur ex aliquid fuga eum quidem. Sit sint consectetur velit. Quisquam quos quisquam cupiditate. Et nemo qui impedit suscipit alias ea. Quia fugiat sit in iste officiis commodi quidem hic quas.</p> -->
      </div><!-- End Section Title -->

      <div class="container">

        <div class="isotope-layout" data-default-filter=".filter-robo" data-layout="masonry" data-sort="original-order">

          <ul class="portfolio-filters isotope-filters" data-aos="fade-up" data-aos-delay="100">

            <li data-filter=".filter-robo" class="filter-active">Robot Learning</li>
            <li data-filter=".filter-ai-vision">Machine Learning & Vision</li>
            <li data-filter=".filter-plan">Planning & Controls</li>
            <li data-filter=".filter-phys-ai">Physical AI & Simulation</li>
            <!-- <li data-filter="*" class="filter-active">All</li> -->
          </ul><!-- End Portfolio Filters -->

          <div class="row gy-4 isotope-container" data-aos="fade-up" data-aos-delay="200">

            <div class="col-12 portfolio-item isotope-item filter-ai-vision">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/distributed-vision-mlops-pipeline">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/mlops_demo.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Spatial-Flow: High-Throughput Distributed MLOps Pipeline</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Orchestrated parallel, asynchronous inference of YOLOv8 and Depth Anything on continuous video
                      streams using <strong>Ray Serve</strong>.</li>
                    <li>Implemented <strong>Scatter-Gather</strong> microservices pattern with <strong>Zero-Copy Ray
                        Plasma</strong> memory for high-throughput intra-cluster data transfer.</li>
                    <li>Deployed fully containerized architecture (<strong>Docker</strong>) on <strong>AWS EKS</strong>
                      for scalable real-time spatial perception.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Ray Serve</span>
                    <span class="skill-badge">AWS</span>
                    <span class="skill-badge">Kubernetes</span>
                    <span class="skill-badge">Depth Anything</span>
                    <span class="skill-badge">Deployment</span>
                    <span class="skill-badge">Docker</span>
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">FastAPI</span>
                    <span class="skill-badge">YOLOv8</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/distributed-vision-mlops-pipeline" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-12 portfolio-item isotope-item filter-ai-vision">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="#"><img src="assets/img/masonry-portfolio/work_2.png"
                      class="img-fluid rounded shadow-sm project-img" loading="lazy" alt=""></a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>3D Vision Pipeline using Foundation Model: TensorRT & ONNX
                      Optimization</strong>
                  </h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Engineered a production-ready <strong>MLE Pipeline</strong> for Stereo Vision, deploying a
                      <strong>Foundation Model</strong> to generate high-fidelity point clouds on edge hardware.
                    </li>
                    <li>Optimized inference latency by <strong>90% </strong> by quantizing and exporting
                      models via <strong>ONNX Runtime</strong> to <strong>TensorRT</strong> engines.</li>
                    <li>Orchestrated deployment using <strong>Docker</strong>, ensuring reproducible,
                      hardware-accelerated execution on <strong>NVIDIA Edge Platforms</strong>.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">ONNX</span>
                    <span class="skill-badge">TensorRT</span>
                    <span class="skill-badge">Docker</span>
                    <span class="skill-badge">Edge AI</span>
                    <span class="skill-badge">PyTorch</span>
                    <span class="skill-badge">Model Optimization</span>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-12 portfolio-item isotope-item filter-robo filter-phys-ai">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="#">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/work_1.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>End-to-End RL Framework for Industrial Manipulator Control with Sim2Real
                      Transfer</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Architected an <strong>End-to-End Reinforcement Learning</strong> framework in <strong>Isaac
                        Sim</strong> for a 6-DoF industrial robot, architecting the full pipeline from training to
                      hardware deployment.</li>
                    <li>Bridged the <strong>Sim-to-Real gap</strong> by calibrating the digital twin via <strong>System
                        Identification</strong>, tuning physics parameters to match hardware dynamics.</li>
                    <li>Engineered a <strong>Dynamic Reward Function</strong> to incentivize smooth approach and precise
                      terminal manipulation for the <strong>PPO Policy</strong>.</li>
                    <li>Integrated a Sim-to-Real policy transfer pipeline, achieving <strong>90% task success</strong>
                      by deploying validated policies directly into the C++ planning stack.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Isaac Sim</span>
                    <span class="skill-badge">Isaac Lab</span>
                    <span class="skill-badge">Reinforcement Learning</span>
                    <span class="skill-badge">Sim2Real</span>
                    <span class="skill-badge">ROS 2</span>
                    <span class="skill-badge">C++</span>
                    <span class="skill-badge">MoveIt</span>
                    <span class="skill-badge">System Identification</span>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-12 portfolio-item isotope-item filter-robo">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/4wheeled-robot-navigation-RL">
                    <img src="assets/img/masonry-portfolio/RL_Navigation.gif"
                      class="img-fluid rounded shadow-sm project-img" loading="lazy" alt=""
                      style="width: 100%; border-radius: 10px;">
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Deep RL for Multi-Agent 4-Wheel Steering Robot Navigation</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Architected RL-based navigation from scratch for 4-wheel steering robots, achieving a
                      <strong>95% success rate</strong> in multi-agent collision avoidance.
                    </li>
                    <li>Modeled <strong>Double-Ackermann kinematics</strong> with realistic actuator dynamics to ensure
                      physically deployable PPO policies.</li>
                    <li>Engineered <strong>dense reward shaping</strong> and custom PPO implementation to eliminate
                      oscillations, enabling smooth stop-at-goal behavior.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Multi-Agent RL</span>
                    <span class="skill-badge">Proximal Policy Optimization (PPO)</span>
                    <span class="skill-badge">Non-Holonomic Control</span>
                    <span class="skill-badge">Collision Avoidance</span>
                    <span class="skill-badge">PyTorch</span>
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">MCAP</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/4wheeled-robot-navigation-RL" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div>



            <!--             <div class="col-lg-4 col-md-6 portfolio-item isotope-item filter-robo">
              <a href="https://github.com/rahulk-99/Humanoid_Imitation-Learning.git"><img src="assets/img/masonry-portfolio/rah_humanoid.gif" class="img-fluid" loading="lazy" alt=""></a>
              <h5 style="text-align: center;"><strong>Humanoid Full-Body Motion Control: Imitation Learning AMP vs. RL PPO</strong></h5>
              <div class="portfolio-info">
                <a href="https://github.com/rahulk-99/Humanoid_Imitation-Learning.git" title="More Details" class="details-link"><i class="bi bi-link-45deg"></i></a>
              </div>
            </div> -->

            <div class="col-12 portfolio-item isotope-item filter-plan filter-phys-ai">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/PrimeScout-MultiRobot-SLAM">
                    <img src="assets/img/masonry-portfolio/slam_map_merge.png"
                      class="img-fluid rounded shadow-sm project-img" loading="lazy" alt=""
                      style="width: 100%; border-radius: 10px;">
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Multi-Agent SLAM & Frontier Exploration System</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Architected decentralized multi-agent system using ROS 2, enabling 3-robot navigation with
                      centralized map merging.</li>
                    <li>Developed a custom C++ Frontier Exploration Node integrating BFS-based clustering and greedy
                      goal allocation, achieving over 95% autonomous map coverage.</li>
                    <li>Established production-grade CI pipeline using Docker and GitHub Actions, achieving over 90%
                      unit test coverage with GTest.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Swarm Intelligence</span>
                    <span class="skill-badge">Distributed Systems</span>
                    <span class="skill-badge">ROS2</span>
                    <span class="skill-badge">Nav2</span>
                    <span class="skill-badge">slam_toolbox</span>
                    <span class="skill-badge">Webots</span>
                    <span class="skill-badge">C++</span>
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">CI/CD</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/PrimeScout-MultiRobot-SLAM" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-12 portfolio-item isotope-item filter-plan filter-phys-ai">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/LQR-CBF-RRT-Star-Planner">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/rrt.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Sampling Based - Kinodynamic Path Planning & Control using RRT* with LQR &
                      CBF</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Implemented LQR, CBF and RRT* for generating kino-dynamically feasible and collision-free paths
                      for an F1 track.</li>
                    <li>Developed a mapping pipeline to process 3D CAD meshes into 2D Occupancy Grids for efficient
                      planning, and validated the generated trajectories by autonomously navigating a TurtleBot in
                      Gazebo.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">MPC</span>
                    <span class="skill-badge">State Estimation</span>
                    <span class="skill-badge">Sensor Fusion</span>
                    <span class="skill-badge">RRT*</span>
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">ROS2</span>
                    <span class="skill-badge">Gazebo</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/LQR-CBF-RRT-Star-Planner" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-12 portfolio-item isotope-item filter-plan filter-phys-ai">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/A-Star-Planning-competition.git">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/A_star.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Graph Search based - Non-Holonomic A-Star Motion Planning for
                      Navigation</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Engineered and validated custom A-star for a differential-drive robot, explicitly modeling
                      <strong>Non-Holonomic Kinematic Constraints</strong> to generate physically executable
                      trajectories.
                    </li>
                    <li>Achieved <strong>Sim2Real Transfer</strong> via ROS2 node, validating collision-free navigation
                      on both <strong>Gazebo</strong> and physical <strong>TurtleBot</strong>.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Heuristic Search</span>
                    <span class="skill-badge">Costmaps</span>
                    <span class="skill-badge">ROS2</span>
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">A*</span>
                    <span class="skill-badge">TurtleBot4</span>
                    <span class="skill-badge">Navigation</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/A-Star-Planning-competition.git" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->

            <div class="col-12 portfolio-item isotope-item filter-plan">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/path_planning_SLAM.git">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/rah_path.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Path Planning: A-Star vs Dijkstra Algorithm</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Implements Dijkstra's and A* algorithms for robot pathfinding in a 2D environment, visualizing
                      node exploration (green), clearance zones (yellow), obstacles (red), and the final path (blue).
                    </li>
                    <li>A* reduces the number of nodes explored by approximately 75% compared to Dijkstra, using a
                      heuristic-guided search to prioritize nodes closer to the goal.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">C++</span>
                    <span class="skill-badge">A*</span>
                    <span class="skill-badge">Dijkstra</span>
                    <span class="skill-badge">Path Planning</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/path_planning_SLAM.git" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->









            <div class="col-12 portfolio-item isotope-item filter-ai-vision">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="#">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/rah_bel.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Underwater Object Detection for Low-Visibility
                      Environments</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Led the development of underwater object detection device for
                      low-visibility environments</li>
                    <li>Engineered a data augmentation pipeline using a GAN to create a large-scale, paired underwater
                      image dataset, overcoming data scarcity.</li>
                    <li>Benchmarked detection models and implemented a consensus strategy combining YOLOv8 for local
                      precision and RT-DETR for global attention, resulting in a 22.8% increase in mAP.</li>
                    <li>Standardized Git workflows and Python best practices to cut code merge conflicts.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">GANs</span>
                    <span class="skill-badge">YOLOv8</span>
                    <span class="skill-badge">RT-DETR</span>
                    <span class="skill-badge">Data Augmentation</span>
                    <span class="skill-badge">MLOps</span>
                    <span class="skill-badge">Computer Vision</span>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->

            <div class="col-12 portfolio-item isotope-item filter-ai-vision">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="#">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/tb4.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Vision-Based Intelligence for TurtleBot4</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Calibrated the camera and implemented ArUco marker-based navigation on TurtleBot4 for precise
                      heading in dynamic competition environments.</li>
                    <li>Developed projective geometry algorithms using Canny edge detection and RANSAC-filtered Hough
                      Transform to compute real-time horizon lines and vanishing points for enhanced scene
                      understanding.</li>
                    <li>Engineered optical flow-based obstacle detection using Lucas-Kanade tracking of Shi-Tomasi
                      features to filter out environment motion and isolate dynamic obstacles.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">OpenCV</span>
                    <span class="skill-badge">ArUco</span>
                    <span class="skill-badge">Optical Flow</span>
                    <span class="skill-badge">Python</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/Perception_Final_Project.git" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->

            <div class="col-12 portfolio-item isotope-item filter-plan">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/Advance_Controllers_MultiMass_System.git"><img
                      src="assets/img/masonry-portfolio/controls.png" class="img-fluid rounded shadow-sm project-img"
                      loading="lazy" alt=""></a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Advance Controller Design for Nonlinear Multi-Mass System</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Devised an LQR controller for nonlinear multi-mass system in MATLAB, achieving stabilization
                      under 5000 N disturbance.</li>
                    <li>Integrated LQG controller with a Luenberger observer in Simulink, leveraging Kalman filtering
                      for robust state estimation.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">MATLAB</span>
                    <span class="skill-badge">Simulink</span>
                    <span class="skill-badge">LQR</span>
                    <span class="skill-badge">LQG</span>
                    <span class="skill-badge">Control Theory</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/Advance_Controllers_MultiMass_System.git" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->

            <div class="col-12 portfolio-item isotope-item filter-plan">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/Quadruped_SpotMicro_Simulation.git">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/rah_quad.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>12-DOF Quadruped Gait control and Locomotion</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Simulated a 4-legged, 12-DOF quadruped robot inspired by SpotMini, integrating custom URDF and
                      realistic physics in Gazebo for stable terrain maneuvering.</li>
                    <li>Developed inverse kinematics control algorithms using ROSPy, enabling precise and stable limb
                      motion</li>
                    <li>Established a trotting gait pattern via open-loop control, achieving stable & coordinated
                      locomotion at ~ 0.3 m/s</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">ROSPy</span>
                    <span class="skill-badge">Gazebo</span>
                    <span class="skill-badge">PyBullet</span>
                    <span class="skill-badge">Inverse Kinematics</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/Quadruped_SpotMicro_Simulation.git" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->

            <div class="col-12 portfolio-item isotope-item filter-ai-vision">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://link.springer.com/article/10.1007/s12572-023-00357-0"><img
                      src="assets/img/masonry-portfolio/rah_journal.png" class="img-fluid rounded shadow-sm project-img"
                      loading="lazy" alt=""></a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>ML-Based Optimization of Fringing Field Effect in MEMS Actuators</strong>
                  </h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Engineered an ML workflow to create a novel predictive model for MEMS actuators , resulting in a
                      first author publication</li>
                    <li>Generated a comprehensive synthetic dataset for MEMS actuator from numerous physics-based FEM
                      simulations using LUA Scripting.</li>
                    <li>Developed a weighted-average ensemble of regressors (Random Forest, SVM, XGBoost) to derive the
                      final model from the simulated data to derive the final predictive model.</li>
                    <li>Benchmarked the model against established methods, reducing prediction error ~40% down to less
                      than 7%</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">Scikit-Learn</span>
                    <span class="skill-badge">LUA</span>
                    <span class="skill-badge">MEMS</span>
                    <span class="skill-badge">FEM</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://link.springer.com/article/10.1007/s12572-023-00357-0" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->


            <div class="col-12 portfolio-item isotope-item filter-ai-vision">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/my_Computer_Vision_library/tree/object_tracking">
                    <!-- rah_track.gif is small (94KB), keeping as GIF or convert if desired. User said 'large GIFs'. 94KB is tiny. -->
                    <img src="assets/img/masonry-portfolio/rah_track.gif"
                      class="img-fluid rounded shadow-sm project-img" loading="lazy" alt="">
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Object Tracking and Motion Analysis Using OpenCV</strong></h5>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/my_Computer_Vision_library/tree/object_tracking"
                      title="More Details" class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">OpenCV</span>
                    <span class="skill-badge">Computer Vision</span>
                  </div>
                </div>
              </div>
            </div>

            <div class="col-12 portfolio-item isotope-item filter-robo">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/Cross_Medium_Drone_Exploration.git"><img
                      src="assets/img/masonry-portfolio/rah_ship.png" class="img-fluid rounded shadow-sm project-img"
                      loading="lazy" alt=""></a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>RL-Based Motion Planning for Aerial-Aquatic
                      Drone using Isaac Sim</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Authored high-fidelity Isaac Sim environment modeling air-water fluid dynamics, achieving 90%
                      sim-to-real correlation.</li>
                    <li>Integrated Pegasus Simulator framework to simulate realistic rotor aerodynamics and contact
                      forces during navigation.</li>
                    <li>Implemented a Soft Actor-Critic RL policy for a hybrid aerial-aquatic drone with an integrated
                      manipulator, solving the
                      complex floating-base control problem.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Isaac Sim</span>
                    <span class="skill-badge">SAC</span>
                    <span class="skill-badge">Reinforcement Learning</span>
                    <span class="skill-badge">Pegasus</span>
                    <span class="skill-badge">Physics Simulation</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/Cross_Medium_Drone_Exploration.git" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->



            <div class="col-12 portfolio-item isotope-item filter-robo filter-phys-ai">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/LLM_Prompt_Robot_Walk.git">
                    <video autoplay loop muted playsinline loading="lazy"
                      class="img-fluid rounded shadow-sm project-img" style="width: 100%; border-radius: 10px;">
                      <source src="assets/img/masonry-portfolio/llm_robot_1.mp4" type="video/mp4">
                      Your browser does not support the video tag.
                    </video>
                  </a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>LLM-Based Control for Autonomous Robot Navigation</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Implemented a robot walking controller <strong>powered by LLMs</strong> using <strong>Few-Shot
                        In-Context Learning</strong>, without requiring fine-tuning.</li>
                    <li>Integrated <strong>LLaMA 4 Maverick-17B</strong> and <strong>Qwen2.5-32B</strong> to predict
                      future actions, <strong>achieving 60% faster inference</strong> speed per action step with LLaMA
                      compared to Qwen</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Embodied AI</span>
                    <span class="skill-badge">Foundation Models</span>
                    <span class="skill-badge">In-Context Learning</span>
                    <span class="skill-badge">LLaMA</span>
                    <span class="skill-badge">Qwen</span>
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">LLM Agent</span>
                    <span class="skill-badge">Robotics</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/LLM_Prompt_Robot_Walk.git" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->

            <div class="col-12 portfolio-item isotope-item filter-robo">
              <div class="row align-items-center">
                <div class="col-md-5">
                  <a href="https://github.com/rahulk-99/Vision_based_Deep_RL_Manipulator.git"><img
                      src="assets/img/masonry-portfolio/rah_control_proj1.png"
                      class="img-fluid rounded shadow-sm project-img" loading="lazy" alt=""></a>
                </div>
                <div class="col-md-7">
                  <h5 class="mb-3"><strong>Vision-based Deep RL Control for Robot Manipulator</strong></h5>
                  <ul class="text-start ps-3 fs-6">
                    <li>Implemented a 2D image-based DQN to control a 3-link robotic arm in Pygame.</li>
                    <li>Designed an adaptive reward function based on Euclidean distance reduction, improving training
                      efficiency by 30% compared to baseline methods.</li>
                    <li>Trained for 1.4 million episodes across five complex settings, achieving a 37% success rate in
                      high-noise environments.</li>
                    <li>Extended the DQN framework for 3D robotic arm control in Gazebo using ROS2, enabling real-time
                      deployment with a Baxter robot.</li>
                  </ul>
                  <div class="resume-skills pb-2">
                    <span class="skill-badge">Python</span>
                    <span class="skill-badge">PyTorch</span>
                    <span class="skill-badge">DQN</span>
                    <span class="skill-badge">ROS2</span>
                    <span class="skill-badge">Gazebo</span>
                    <span class="skill-badge">Visual Reinforcement Learning</span>
                    <span class="skill-badge">Deep Q-Networks (DQN)</span>
                    <span class="skill-badge">Robotic Manipulation</span>
                    <span class="skill-badge">Domain Randomization</span>
                  </div>
                  <div class="portfolio-info mt-3">
                    <a href="https://github.com/rahulk-99/Vision_based_Deep_RL_Manipulator.git" title="More Details"
                      class="details-link"><i class="bi bi-link-45deg fs-4"></i></a>
                  </div>
                </div>
              </div>
            </div><!-- End Portfolio Item -->

            <!-- <div class="col-lg-4 col-md-6 portfolio-item isotope-item filter-perception">
              <a href="https://github.com/rahulk-99/my_Computer_Vision_library/tree/edge_detection"><img src="assets/img/masonry-portfolio/rah_edge.gif" class="img-fluid" loading="lazy" alt=""></a>
              <h5 style="text-align: center;"><strong>Edge Detection Using Hough Transform using OpenCV</strong></h5>
              <div class="portfolio-info">
                <a href="https://github.com/rahulk-99/my_Computer_Vision_library/tree/edge_detection" title="More Details" class="details-link"><i class="bi bi-link-45deg"></i></a>
              </div>
            </div> -->

            <!-- <div class="col-lg-4 col-md-6 portfolio-item isotope-item filter-ml">
              <a href=""><img src="assets/img/masonry-portfolio/" class="img-fluid" loading="lazy" alt=""></a>
              <h5 style="text-align: center;"></h5>
              <div class="portfolio-info">
                <a href="" title="More Details" class="details-link"><i class="bi bi-link-45deg"></i></a>
              </div>
            </div> -->

          </div><!-- End Portfolio Container -->

        </div>

      </div>

    </section><!-- /Portfolio Section -->


    <!-- <section id="extra" class="services section">

      
      <div class="container section-title" data-aos="fade-up">
        <h2>Publication</h2>
        <p>Kumar, Rahul, Dileesh Parayil, and Amar K. Gaonkar. "Novel fringing field model for MEMS resonators." International Journal of Advances in Engineering Sciences and Applied Mathematics 16.2 (2024): 176-182.</p>
      </div>

    </section> -->

    <section id="extra" class="services section">
      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Publication</h2>
        <div class="publication-item d-flex align-items-center">
          <a href="https://link.springer.com/article/10.1007/s12572-023-00357-0" target="_blank">
            <img src="assets/img/masonry-portfolio/SN_2.png" alt="Springer Nature Logo" width="50" height="auto"
              class="me-3">
          </a>
          <div>
            <p>
              <strong>Kumar, Rahul</strong>, Dileesh Parayil, and Amar K. Gaonkar.
              <a href="https://link.springer.com/article/10.1007/s12572-023-00357-0" target="_blank">
                "Novel fringing field model for MEMS resonators."
              </a>
              International Journal of Advances in Engineering Sciences and Applied Mathematics 16.2 (2024): 176-182.
            </p>
          </div>
        </div>
      </div><!-- End Section Title -->
    </section><!-- /Publication -->






    <!-- Services Section -->
    <section id="extra" class="services section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Activities</h2>
        <!-- <p>Magnam dolores commodi suscipit. Necessitatibus eius consequatur ex aliquid fuga eum quidem. Sit sint consectetur velit. Quisquam quos quisquam cupiditate. Et nemo qui impedit suscipit alias ea. Quia fugiat sit in iste officiis commodi quidem hic quas.</p> -->
      </div><!-- End Section Title -->

      <div class="container">

        <div class="row gy-4">

          <div class="col-lg-4 col-md-4" data-aos="fade-up" data-aos-delay="100">
            <div class="service-item item-cyan position-relative">
              <img src="assets/img/masonry-portfolio/expo.jpg" class="img-fluid" alt="Icon" href="">
              <a href="https://expo.scsp.ai/" class="stretched-link">
                <h3>Attended AI+ Expo 2025 in Washington, D.C.</h3>
              </a>
            </div>
          </div><!-- End Service Item -->

          <div class="col-lg-4 col-md-4" data-aos="fade-up" data-aos-delay="100">
            <div class="service-item item-cyan position-relative">
              <img src="assets/img/masonry-portfolio/rah_frc.jpg" class="img-fluid" alt="Icon" href="">
              <a href="https://www.firstchesapeake.org/" class="stretched-link">
                <h3>Robot Inspector at First Robotics Competition 2025</h3>
              </a>
            </div>
          </div><!-- End Service Item -->

          <div class="col-lg-4 col-md-4" data-aos="fade-up" data-aos-delay="100">
            <div class="service-item item-cyan position-relative">
              <img src="assets/img/masonry-portfolio/rah_conf.jpg" class="img-fluid" alt="Icon" href="">
              <a href="https://istam.iitkgp.ac.in/resources/2022/proceedings/Abstract/PA0152.pdf"
                class="stretched-link">
                <h3>Presented Paper at International Conference - 67th ISTAM at IIT Mandi </h3>
              </a>
            </div>
          </div><!-- End Service Item -->





        </div>

      </div>

    </section><!-- /Services Section -->


  </main>

  <footer id="footer" class="footer position-relative light-background">
    <div class="container">
      <h4 class="sitename">Rahul Kumar</h4>
      <!-- <p>Et aut eum quis fuga eos sunt ipsa nihil. Labore corporis magni eligendi fuga maxime saepe commodi placeat.</p> -->
      <div class="social-links d-flex justify-content-center">
        <a href="mailto:rahuliitdh789@gmail.com"><i class="bi bi-envelope"></i></a>
        <a href="https://github.com/rahulk-99"><i class="bi bi-github"></i></a>
        <a href="https://www.linkedin.com/in/rahul-kumar4/"><i class="bi bi-linkedin"></i></a>
      </div>
      <div class="container">
        <div class="credits">
          Designed & Developed by <strong>Rahul Kumar</strong> | Template by <a
            href="https://bootstrapmade.com/">BootstrapMade</a>
        </div>
      </div>
    </div>
  </footer>

  <!-- Scroll Top -->
  <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i
      class="bi bi-arrow-up-short"></i></a>

  <!-- Preloader -->
  <div id="preloader"></div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js" defer></script>
  <script src="assets/vendor/php-email-form/validate.js" defer></script>
  <script src="assets/vendor/aos/aos.js" defer></script>
  <script src="assets/vendor/typed.js/typed.umd.js" defer></script>
  <script src="assets/vendor/purecounter/purecounter_vanilla.js" defer></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js" defer></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js" defer></script>
  <script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js" defer></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js" defer></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js" defer></script>

  <!-- Main JS File -->
  <script src="assets/js/dark-mode.js?v=1.1" defer></script>
  <script src="assets/js/main.js?v=1.1" defer></script>

</body>

</html>